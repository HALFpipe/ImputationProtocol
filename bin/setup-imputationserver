#!/bin/bash

VERBOSE=1

run_cmd() {
    cmd="$*"

    printf '%s\n' --------------------

    if [ "$VERBOSE" = "1" ]; then
	printf "$cmd\n"
    fi

    eval "$@"

    EXIT_CODE=$?

    if [[ $EXIT_CODE -gt 0 ]]; then
	echo "ERROR: command exited with nonzero status $EXIT_CODE"
    fi

    printf '%s\n' --------------------

    return $EXIT_CODE
}

# code starts here

run_cmd mkdir -p -v /data/cloudgene /data/downloads
run_cmd cp -rnv /opt/cloudgene/* /data/cloudgene/

export PATH=/data/cloudgene:${PATH}
export HADOOP_CONF_DIR=/data/hadoop/config

run_cmd cloudgene verify-cluster

run_cmd wget --continue -O /data/downloads/imputationserver.zip "https://github.com/genepi/imputationserver/releases/download/v1.6.8/imputationserver.zip"
run_cmd wget --continue -O /data/downloads/1000genomes-phase3.zip "https://imputationserver.sph.umich.edu/static/downloads/releases/1000genomes-phase3-3.0.0.zip"

run_cmd cloudgene install /data/downloads/imputationserver.zip
run_cmd cloudgene install /data/downloads/1000genomes-phase3.zip

run_cmd "sed -i \"s/value: auto/value: password/g\" /data/cloudgene/apps/imputationserver/*/*.yaml"

run_cmd find /data/cloudgene/apps -type d -exec chmod ugo+w {} +  # need to be writable because it will be used as a temp dir
run_cmd find /data/cloudgene/apps -type f -exec chmod ugo-w {} +  # should not be writable, or cloudgene will delete the files after import to hadoop hdfs

run_cmd mkdir -p -v /data/input /data/output
